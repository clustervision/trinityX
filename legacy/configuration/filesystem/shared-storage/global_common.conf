# TrinityX DRBD configuration file

# References:
# https://www.drbd.org/en/doc/users-guide-84/s-throughput-tuning
# https://www.drbd.org/en/doc/users-guide-84/s-latency-tuning
# https://blogs.linbit.com/p/128/drbd-sync-rate-controller/
# https://blogs.linbit.com/p/443/drbd-sync-rate-controller-2/


global {
    usage-count no;
}


common {
    startup {
        # Wait-for-connection timeout.
        wfc-timeout 15;
        
        # Wait for connection timeout, if this node was a degraded cluster.
        degr-wfc-timeout 15;
        
        # Wait for connection timeout, if the peer was outdated.
        outdated-wfc-timeout 15;
    }
    
    
    disk {
        # Disk barriers have a large performance hit and are disabled by default
        # due to potential issues with certain kernels, but just in case:
        
        disk-barrier no;
        
        # Disk flushes are enabled by default. They have a performance impact,
        # but the alternative (letting IO drain) assumes that there is NO
        # VOLATILE CACHE between DRBD and the media. If this is the case, your
        # RAID controller is battery backed and the drive caches are disabled,
        # you may get a bit more performance by uncommenting this line:
        
        #disk-flushes no;
        
        # Number of activity log extents (hot area). A higher number offers
        # better performance at the cost of a longer resync. The calculation of
        # the real maximum number of extents is quite complex, see the man page.
        # This is the maximum for DRBD 8.4 with the default ring buffer size.
        # That covers about 25GB worth of hot area (6433 * 4MB)
        
        al-extents 6433;
        
        #-----------------------------------------------------------------------
        
        # Dynamic resync speed controller configuration
        # ---------------------------------------------
        # Disabled by default in 8.3 and before, enabled in 8.4 and after.
        # Note: the sync-rate controller is used for controlling the bandwidth
        # used during resynchronization, not normal replication.
        
        # Interval (in deciseconds) used for average speed calculations.
        # Recommended value is 10x ping RTT between the two controllers.
        # Default is 20 (2 seconds). 0 disables it entirely.
        
        c-plan-ahead 20;
        
        # Static resync rate
        # If the dynamic resync speed controller is used, this value is only
        # used for an initial estimate of the resync speed. Recommendation is
        # to set it to 1/3 of the maximum write speed of the DRBD data path
        # (network, HBA, expander, disks, etc).
        # If the dynamic controller is off, then this is the maximum resync
        # speed between the controllers.
        
        resync-rate 25M;
        
        # Minimum and maximum badwidth used during a resync.
        # Set the c-max-rate to the maximum write speed that the DRBD data path
        # on the slowest of the controllers, can handle.
        # C-min-rate is the minimum guaranteed bandwidth when application I/O,
        # which has higher priority, occurs. If set to 0, then app I/O detection
        # is disabled and the resync consumes as much BW as possible, up to the
        # c-max-rate amount.
        # If c-min-rate == 0 and c-max-rate == maximum the HW can handle, you
        # better make sure that any resync happens when the system is offline...
        
        c-min-rate 10M;
        c-max-rate 70M;
        
        # DRBD has two ways of avoiding being too greedy on its resources when
        # trying to resync. Both of them require live hardware tests.
        
        # The first one is to limit the amount of in-flight data, rather than
        # saturating the buffers. That way when an app I/O comes in, it doesn't
        # have to wait until the full buffers are transferred, which improves
        # latency a bit.
        # This should be set to the minimum that still allows you to reach full
        # datapath bandwidth on an idle system.
        # 100k is recommended as a good starting point.
        # If set to 0, the second method is used.
        
        c-fill-target 0;
        
        # The second way is measure the delay in response between the
        # controllers. When it becomes longer than this value (the latency
        # increases), it is assumed that the data path is at full capacity and
        # the resync process throttles down. In effect it's the maximum
        # acceptable latency. Warning: sensitive to network issues!
        # 5x ping RTT is recommended as a good starting point.
        
        c-delay-target 10;
    }
    
    
    net {
        # Protocol C: write IO is reported as completed, if it has reached both
        # local and remote disks (synchronous replication).
        
        protocol C;
        
        # Maximal number of buffer pages allocated by DRBD's receiver thread,
        # maximal number of write requests between two write barriers.
        # They should be set to the same value.
        
        max-buffers 8192;
        max-epoch-size 8192;
        
        # Buffer used to store packets sent to the secondary node, which are not
        # yet acknowledged by the secondary node. 0 (default) lets the kernel
        # autotune it.
        
        #sndbuf-size 1024k;
        #rcvbuf-size 2048k;
    }
}

