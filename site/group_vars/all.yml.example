---
# This file contains variables that are global to all playbooks
# in this repository.

# Any alerts, events and notifications will be sent to this email address:

administrator_email: 'root@localhost'


# -----------------------------------------------------------------------
# Trinity version number

trix_version: '14.1'

# What stream to follow. Stable is the default and recommended.
trix_stream: 'stable'

# -----------------------------------------------------------------------
# Project ID or string that'll show up in the default
# prompt on the controllers.

project_id: '000000'


#########################################################################
#                         High Availability                             #
#########################################################################
# -----------------------------------------------------------------------
# Do we want HA?
# Set to 'False' to disable HA, set to 'True' to enable it.

ha: false

# -----------------------------------------------------------------------
# whether we want to use ipmi for H/A fencing

enable_ipmilan_fencing: true

# -----------------------------------------------------------------------
# IPMI H/A fencing credentials. Used in conjunction with HA
# Being ignored if setting enable_ipmilan_fencing is set to false

fence_ipmilan_login: 'user'
fence_ipmilan_passwd: 'password'

# -----------------------------------------------------------------------
# Whether or not to configure the corosync heartbeat link (ring 1)
# Requires correct configured trix_ctrlX_heartbeat_ip.

enable_heartbeat_link: true

#########################################################################


# -----------------------------------------------------------------------
# Should we use content of the installation CD/USB-stick
# to install TrinityX

local_install: false


# -----------------------------------------------------------------------
# A domain name to be assigned to the controller(s) and nodes
# on the internal network.
# Luna's provisioning network name will be set to the same value.

trix_domain: cluster


# -----------------------------------------------------------------------
# Internal network definitions and the DHCP range used to to PXE boot
# the compute nodes. Also Infiniband IPoIB and bmc/ipmi networks.

trix_cluster_net: 10.141.0.0
trix_cluster_netprefix: 16
trix_cluster_dhcp_start: 10.141.128.0
trix_cluster_dhcp_end: 10.141.140.0

trix_infiniband_net: 10.149.0.0
trix_infiniband_netprefix: 16

trix_bmc_net: 10.148.0.0
trix_bmc_netprefix: 16


# -----------------------------------------------------------------------
# Default hostname and IP for the controller
# In an H/A pair, those are the hostname and IP for the first controller.
# Those variables are required, with or without HA.

trix_ctrl1_ip: 10.141.255.254
trix_ctrl1_bmcip: 10.148.255.254
trix_ctrl1_heartbeat_ip: 10.146.255.254
trix_ctrl1_hostname: controller1

# In a non-H/A setup, all of the following variables will be ignored:
# - the variables for CTRL will be set to the same as CTRL1;
# - the variables for CTRL2 will be ignored.

# Hostname and IP of the second controller

trix_ctrl2_ip: 10.141.255.253
trix_ctrl2_bmcip: 10.148.255.253
trix_ctrl2_heartbeat_ip: 10.146.255.253
trix_ctrl2_hostname: controller2

# Floating hostname and IP

trix_ctrl_ip: 10.141.255.252
trix_ctrl_hostname: controller

# -----------------------------------------------------------------------
# optional hostname/fqdn to be used for services that are outward facing,
# like open-ondemand. This hostname is in most scenarios the fqdn of the host,
# but this can be overridden if external resolution/name differs.
# The fqdn of the host will be used when Left empty or open.

trix_external_fqdn: ''


# -----------------------------------------------------------------------
# DNS forwarders.

trix_dns_forwarders: 
  - "8.8.8.8"
  - "8.8.4.4"


# -----------------------------------------------------------------------
# Default search domains to be added to /etc/resolv.conf

resolv_search_domains: '{{ trix_domain }} ib ipmi'


# -----------------------------------------------------------------------
# Path to which the standard TrinityX files will be installed.
# If not set, it will default to /trinity

trix_root: '/trinity'

# The TrinityX root contains multiple subdirectories for different uses:
# - trix_images For the compute node images
# - trix_shared for everything shared by the controllers to the nodes
# - trix_local for configuration files specific to each machine
# - trix_home for the user home directories
#
# Since trix_local will also house the monitoring data, it is recommended to
# put this on a seperate partition for large installations or extensive
# monitoring setups.
# The partitioning on the controller must be set up before starting the installation.
#
# By default those exist under trix_root. There are some cases where this is not
# desirable; the following variables allow you to override the default paths.
# WARNING: use with caution! It's not well tested and there may be some issues
# here and there...

trix_images: '{{ trix_root }}/images'
trix_shared: '{{ trix_root }}/shared'
trix_local: '{{ trix_root }}/local'
trix_ha: '{{ trix_root }}/ha'
trix_sync: '{{ trix_local }}/sync'
trix_luna: '{{ trix_local }}/luna'
trix_etc: '{{ trix_local }}/etc'
trix_sbin: '{{ trix_local }}/sbin'
trix_ood: '{{ trix_local }}/ondemand'
trix_ssl: '{{ trix_etc }}/ssl'
trix_home: '{{ trix_root }}/home'
trix_repos: '{{ trix_root }}/repos'
trix_ohpc: '{{ trix_root }}/ohpc'
trix_licenses: '{{ trix_shared }}/licenses'
trix_docs: '{{ trix_shared }}/docs'
trix_examples: '{{ trix_shared }}/examples'
trix_modulefiles: '{{ trix_shared }}/modulefiles'


# -----------------------------------------------------------------------
# Backend type and block device to use for the specified backend.
# Works in conjunction with H/A. Combinations are supported.
# 'type' can be: drbd, nfs, iscsi or direct (e.g. multipath).
# 'fstype' can be: ext4, xfs or any regular filesystem
#                  but also lvm or zfs. In this case
#                  partitions have to be defined.

# --- examples:
#
# shared_fs_disks: 
#   - name: 'ZFS1'
#     type: 'drbd'
#     disk: '/dev/sda4'
#     device: '/dev/drbd4'
#     fstype: 'zfs'
#     partitions:
#     - name: '/trinity/other'
#       options: '-o xattr=sa'
#
#   - name: 'LVM1'
#     type: 'drbd'
#     disk: '/dev/sda3'
#     device: '/dev/drbd3'
#     fstype: 'lvm'
#     partitions:
#     - mount: '{{ trix_shared }}'
#       size: '20480M'
#       fstype: 'ext4'
#       options: '-b 4096'
#     - mount: '{{ trix_ohpc }}'
#       size: '10240M'
#       fstype: 'ext4'
#       options: '-b 4096'
#
#   - name: 'Home directories'
#     mount: '{{ trix_home }}'
#     type: 'drbd'
#     disk: '/dev/sda2'
#     device: '/dev/drbd2'
#     fstype: 'ext4'
#     options: '-b 4096'
#
#   - name: 'LVM2'
#     type: 'iscsi'
#     fstype: 'lvm'
#     portal: '192.168.0.1'
#     target: 'iqn.2003-01.org.linux-iscsi.iscsi-host.x8664:sn.693ca380655e'
#     partitions:
#     - mount: '/trinity/ext1'
#       size: '8192M'
#       fstype: 'ext4'
#       options: '-b 4096'
#
#   - name: 'LVM3'
#     type: 'direct'
#     device: /dev/sdz
#     fstype: 'lvm'
#     partitions:
#     - mount: '/trinity/ext2'
#       size: '16384M'
#       fstype: 'ext4'
#       options: '-b 4096'
#
#   - name: '{{ trix_home }}'
#     mount: '{{ trix_home }}'
#     type: 'nfs'
#     remote: '192.168.0.1:/homes'
#     options: 'nfsvers=4,rw,retrans=4,_netdev'
#

# As an absolute bare minimum trix_ha requires a shared disk.
# For trix_home, trix_shared and trix_ohpc it comes extremely highly
# recommended to have a shared disk as well. Below is what's
# considered a standard shared disk configuration. Note that /dev/vda
# needs to be configured to be a real disk which is 100% equal
# on each controller when using drbd.

shared_fs_disks:
  - name: 'trinityx'
    type: 'drbd'
    disk: '/dev/vda'
    device: '/dev/drbd0'
    fstype: 'zfs'
    partitions:
    - mount: '{{ trix_home }}'
      options: '-o xattr=sa'
    - mount: '{{ trix_shared }}'
      options: '-o xattr=sa'
    - mount: '{{ trix_ohpc }}'
      options: '-o xattr=sa'
    - mount: '{{ trix_ha }}'
      options: '-o xattr=sa'
    


# -----------------------------------------------------------------------
# Luna credentials. These should be changed.

luna_username: luna
luna_password: luna


# luna's default communication protocol
# options are: http and https
# by default the system is using the certificates provides and signed by self-signed CV root ca
# in this case we do not verify the certificate

luna_protocol: https
luna_verify_certificate: false


# -----------------------------------------------------------------------
# Default firewalld configuration
# Only public tcp/udp ports are allowed on the public interfaces
# whereas everything is allowed on the trusted interfaces

firewalld_public_interfaces: [ens3]
firewalld_trusted_interfaces: [ens6]
firewalld_public_tcp_ports: [22, 443]
firewalld_public_udp_ports: []

# *Note* that depending on selection of roles, the following ports will be open as well:
# Grafana:       3000/tcp
# Uchiwa/Sensu:  3001/tcp
# Open-ondemand: 8080/tcp


# -----------------------------------------------------------------------
# Admin group is used to give privileges to the members of this group.
# It's used for logins, ood and others.

admin_group: admins


# -----------------------------------------------------------------------
# Path in which the generated certificates for the cluster will be installed.
# ssl_cert_group refers to the UNIX group that has read access to the certs.

ssl_cert_path: '{{ trix_local }}/etc/ssl'
ssl_ca_cert: '{{ ssl_cert_path }}/cluster-ca.crt'
ssl_cert_group: ssl


# -----------------------------------------------------------------------
# OpenHPC repositories. commonly used for openhpc and schedulers

# --- for EL8:
el8_openhpc_repositories:
  - name: base
    repo: http://repos.openhpc.community/OpenHPC/2/EL_8/
    gpgcheck: false
  - name: updates
    repo: http://repos.openhpc.community/OpenHPC/2/update.2.6.1/EL_8/
    gpgcheck: false

# --- for EL9:
el9_openhpc_repositories:
  - name: base
    repo: https://updates.clustervision.com/trinityx/external/openhpc/redhat/9
    gpgcheck: false


# -----------------------------------------------------------------------
# set the default target for images. 
# available: graphical and multi-user

image_default_target: 'multi-user'


# =======================================================================
# The following variables give the ability to enable or disable
# certain features in TrinityX:


# -----------------------------------------------------------------------
# Whether or not to enable SELinux throughout the cluster

enable_selinux: true


# -----------------------------------------------------------------------
# Install docker daemon, registry and utilities on the cluster

enable_docker: false


# -----------------------------------------------------------------------
# List of additional environment modules to install

additional_env_modules: []


# -----------------------------------------------------------------------
# Install userspace packages from OpenHPC project

enable_openhpc: true


# -----------------------------------------------------------------------
# Default workload manager. Currently supported are:
# - slurm
# - pbspro

workload_manager: 'slurm'

# -----------------------------------------------------------------------
# Whether or not to enable Slurm PAM module
# If enabled, sssd's ldap filters will be disabled on the compute nodes

enable_slurm_pam: true


# -----------------------------------------------------------------------
# Enable VNC to nodes on Open OnDemand

enable_ood_vnc: true


# -----------------------------------------------------------------------
# Choose the auth provider for Open OnDemand
# - pam
# - dex  ( only openldap is configured for dex )
# Note that setting enable_authentication to false, implies 'pam' here.

ood_authentication_provider: 'dex' 


# -----------------------------------------------------------------------
# whether we need to configure our ldap, sssd and other things (true)
# or we use an external manually configured authentication mechanism (false)

enable_authentication: true



# -----------------------------------------------------------------------
# DO NOT REMOVE: yml check: 140101
